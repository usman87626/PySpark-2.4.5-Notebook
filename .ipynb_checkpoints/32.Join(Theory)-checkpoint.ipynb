{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Transformations:\n",
    "Join operations are analogous to the JOIN operations you routinely see in SQL programming. Join\n",
    "functions combine records from two RDDs based on a common field, a key. Because join functions\n",
    "in Spark require a key to be defined, they operate on key/value pair RDDs.\n",
    "\n",
    "The following is a quick refresher on joins—which you may want to skip if you have a relational\n",
    "database background:\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        A <b>join</b> operates on two different datasets, where one field in each dataset is nominated as\n",
    "a key (a join key). The datasets are referred to in the order in which they are specified. For\n",
    "instance, the first dataset specified is considered the left entity or dataset, and the second\n",
    "dataset specified is considered the right entity or dataset.\n",
    "    </li>\n",
    "    <li>\n",
    "       An <b>inner join</b>, often simply called a join (where the “inner” is inferred), returns all elements\n",
    "or records from both datasets, where the nominated key is present in both datasets. \n",
    "    </li>\n",
    "    <li>\n",
    "        An <b>outer join</b> does not require keys to match in both datasets. Outer joins are implemented\n",
    "as either a left outer join, a right outer join, or a full outer join.\n",
    "    </li>    \n",
    "    <li>\n",
    "       A <b>left outer join</b> returns all records from the left (or first) dataset along with matched records\n",
    "only (by the specified key) from the right (or second) dataset. \n",
    "    </li>\n",
    "    <li>\n",
    "        A <b>right outer join</b> returns all records from the right (or second) dataset along with matched\n",
    "records only (by the specified key) from the left (or first) dataset.\n",
    "    </li>    \n",
    "    <li>\n",
    "        A <b>full outer join</b> returns all records from both datasets whether there is a key match or not.\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "Joins are some of the most commonly required transformations in the Spark API, so it is imperative\n",
    "that you understand these functions and become comfortable using them.\n",
    "\n",
    "To illustrate the use of the different join types in the Spark RDD API, let’s consider a dataset from\n",
    "a fictitious retailer that includes an entity containing stores and an entity containing salespeople,\n",
    "loaded into RDDs, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext,SparkConf\n",
    "\n",
    "configure = SparkConf().setAppName(\"JOINS\").setMaster(\"local\")\n",
    "sc = SparkContext(conf = configure)\n",
    "\n",
    "stores = sc.parallelize(\n",
    "                        [\n",
    "                        (100, 'Boca Raton'),\n",
    "                        (101, 'Columbia'),\n",
    "                        (102, 'Cambridge'),\n",
    "                        (103, 'Naperville')\n",
    "                        ]\n",
    ")\n",
    "# stores schema (store_id, store_location)\n",
    "salespeople = sc.parallelize(\n",
    "                              [\n",
    "                                (1, 'Henry', 100),\n",
    "                                (2, 'Karen', 100),\n",
    "                                (3, 'Paul', 101),\n",
    "                                (4, 'Jimmy', 102),\n",
    "                                (5, 'Janice', None)\n",
    "                              ]\n",
    ")\n",
    "# salespeople schema (salesperson_id, salesperson_name, store_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the coming notebook lectures, we will look at the available join transformations in Spark, their usage, and some\n",
    "examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
