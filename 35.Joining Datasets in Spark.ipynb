{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Datasets in Spark:\n",
    "For this example you will use data from the Bay Area Bike Share Data Challenge. The Bay Area Bike\n",
    "Share program enables members to pick up bikes from designated stations and then drop off the\n",
    "bikes at the same station or a different one. Bay Area Bike Share has made trip data available for\n",
    "public use through the group’s Open Data program. For more information, see these sites:\n",
    "\n",
    "1.   [Open-Data](http://www.bayareabikeshare.com/open-data) \n",
    " \n",
    "2.   [System-Data](https://www.fordgobike.com/system-data )\n",
    "\n",
    "\n",
    "To make your job easier, the data files for this exercise are available in this book’s AWS S3 bucket:\n",
    "\n",
    "1.     [station-csv](https://s3.amazonaws.com/sparkusingpython/bike-share/stations/stations.csv)\n",
    "\n",
    "2.     [status-csv](https://s3.amazonaws.com/sparkusingpython/bike-share/status/status.csv)\n",
    "\n",
    "3.     [trips-csv](https://s3.amazonaws.com/sparkusingpython/bike-share/trips/trips.csv)\n",
    "\n",
    "4.     [weather-csv](https://s3.amazonaws.com/sparkusingpython/bike-share/weather/weather.csv)\n",
    "\n",
    "You can download these files to your local Spark installation and access them locally. For this\n",
    "exercise, you should download the files and store them in your $SPARK_HOME/data directory as\n",
    "follows:\n",
    "\n",
    "<pre>\n",
    "   - data\n",
    "      -bike-share\n",
    "         -stations\n",
    "            stations.csv\n",
    "         -status\n",
    "            status.csv\n",
    "         -trips\n",
    "            trips.csv\n",
    "         -weather\n",
    "           weather.csv\n",
    "</pre>\n",
    "\n",
    "In this exercise, you will use this data to return the average number of bikes available by the hour\n",
    "for one week (February 22 to February 28) for stations located in the San Jose area only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.master', 'local'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.id', 'local-1590559680408'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'joining-datasets'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.port', '60737'),\n",
       " ('spark.driver.host', 'DESKTOP-I7971JS')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext,SparkConf\n",
    "\n",
    "configure = SparkConf().setAppName(\"joining-datasets\").setMaster(\"local\")\n",
    "sc = SparkContext(conf = configure)\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"joining-datasets\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = sc.textFile('file:///C:\\\\Spark\\\\data\\\\bike-share\\\\stations')\n",
    "#FOR LINUX USERS,\n",
    "# stations = sc.textFile(\"file://opt/Spark/data/bike-share/stations\")\n",
    "status = sc.textFile('file:///C:\\\\Spark\\\\data\\\\bike-share\\\\status')\n",
    "#FOR LINUX USERS,\n",
    "# status = sc.textFile(\"file://opt/Spark/data/bike-share/status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10,9,6,\"2015-02-28 23:59:01\"',\n",
       " '10,9,6,\"2015-02-28 23:58:02\"',\n",
       " '10,9,6,\"2015-02-28 23:57:02\"',\n",
       " '10,8,7,\"2015-02-28 23:56:02\"']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 9, 2015, 2, 28, 23),\n",
       " (10, 9, 2015, 2, 28, 23),\n",
       " (10, 9, 2015, 2, 28, 23),\n",
       " (10, 8, 2015, 2, 28, 23),\n",
       " (10, 8, 2015, 2, 28, 23)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the status data into discrete fields, projecting only the fields necessary, and\n",
    "# decompose the date string so that you can filter records by date more easily in the next step:\n",
    "status2 = status.map(lambda x:x.split(',')) \\\n",
    "                .map(lambda x: (x[0], x[1], x[2], x[3].replace('\"',''))) \\\n",
    "                .map(lambda x: (x[0], x[1], x[2], x[3].split(' '))) \\\n",
    "                .map(lambda x: (x[0], x[1], x[2], x[3][0].split('-'), x[3][1].split(':'))) \\\n",
    "                .map(lambda x: (int(x[0]), int(x[1]), int(x[3][0]), int(x[3][1]), int(x[3][2]),int(x[4][0])))\n",
    "status2.take(5)\n",
    "#Schema after operations:\n",
    "#[(Station_id,bikes_available,year,month,day,hour)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 9, 23), (10, 9, 23), (10, 9, 23), (10, 8, 23), (10, 8, 23)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because status.csv is the biggest of the datasets (more than 36 million records), restrict\n",
    "# the dataset to only the dates required and then drop the date fields because they are no\n",
    "# longer necessary:\n",
    "status3 = status2.filter(lambda x: x[2]==2015 and x[3]==2 and x[4]>=22) \\\n",
    "                .map(lambda x: (x[0] , x[1],x[5]))\n",
    "\n",
    "status3.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,San Jose Diridon Caltrain Station,37.329732,-121.901782,27,San Jose,8/6/2013',\n",
       " '3,San Jose Civic Center,37.330698,-121.888979,15,San Jose,8/5/2013',\n",
       " '4,Santa Clara at Almaden,37.333988,-121.894902,11,San Jose,8/6/2013',\n",
       " '5,Adobe on Almaden,37.331415,-121.8932,19,San Jose,8/5/2013']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'San Jose Diridon Caltrain Station'),\n",
       " (3, 'San Jose Civic Center'),\n",
       " (4, 'Santa Clara at Almaden'),\n",
       " (5, 'Adobe on Almaden'),\n",
       " (6, 'San Pedro Square'),\n",
       " (7, 'Paseo de San Antonio'),\n",
       " (8, 'San Salvador at 1st'),\n",
       " (9, 'Japantown'),\n",
       " (10, 'San Jose City Hall'),\n",
       " (11, 'MLK Library'),\n",
       " (12, 'SJSU 4th at San Carlos'),\n",
       " (13, 'St James Park'),\n",
       " (14, 'Arena Green / SAP Center'),\n",
       " (16, 'SJSU - San Salvador at 9th'),\n",
       " (80, 'Santa Clara County Civic Center'),\n",
       " (84, 'Ryland Park')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the stations dataset to include only stations where landmark='San Jose':\n",
    "stations2 = stations.map(lambda x:x.split(',')) \\\n",
    "                    .filter(lambda x:x[5]=='San Jose') \\\n",
    "                    .map(lambda x: (int(x[0]), x[1]))\n",
    "\n",
    "stations2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert both RDDs to key/value pair RDDs to prepare for a join() operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_kv = status3.keyBy(lambda x: x[0])\n",
    "stations_kv = stations2.keyBy(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the status_kv key/value pair RDD to the stations_kv key/value pair RDD by their\n",
    "keys (station_id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, ((10, 9, 23), (10, 'San Jose City Hall'))),\n",
       " (10, ((10, 9, 23), (10, 'San Jose City Hall'))),\n",
       " (10, ((10, 9, 23), (10, 'San Jose City Hall'))),\n",
       " (10, ((10, 8, 23), (10, 'San Jose City Hall'))),\n",
       " (10, ((10, 8, 23), (10, 'San Jose City Hall')))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = status_kv.join(stations_kv)\n",
    "joined.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the joined RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 9, 23, 'San Jose City Hall'),\n",
       " (10, 9, 23, 'San Jose City Hall'),\n",
       " (10, 9, 23, 'San Jose City Hall'),\n",
       " (10, 8, 23, 'San Jose City Hall'),\n",
       " (10, 8, 23, 'San Jose City Hall')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = joined.map(lambda x: (x[0], x[1][0][1], x[1][0][2], x[1][1][1]))\n",
    "cleaned.take(5)\n",
    "# The schema for the cleaned RDD is as follows:\n",
    "# [(station_id,bikes_available,hour,name),...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a key/value pair with the key as a tuple consisting of the station name and the hour\n",
    "and then compute the averages by each hour for each station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('San Jose City Hall', 23), 7.29047619047619),\n",
       " (('San Jose City Hall', 21), 7.383333333333334),\n",
       " (('San Jose City Hall', 19), 7.35),\n",
       " (('San Jose City Hall', 17), 7.038095238095238),\n",
       " (('San Jose City Hall', 15), 6.754761904761905)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgbyhour = cleaned.keyBy(lambda x: (x[3],x[2])) \\\n",
    "                   .mapValues(lambda x: (x[1], 1)) \\\n",
    "                   .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
    "                   .mapValues(lambda x: (x[0]/x[1]))\n",
    "avgbyhour.take(5)\n",
    "\n",
    "# The schema for the cleaned RDD is as follows:\n",
    "# [((name,hour),bikes_available),...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top 10 averages by station and hour by using the sortBy() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('San Jose Diridon Caltrain Station', 17, 16.590476190476192),\n",
       " ('San Jose Diridon Caltrain Station', 7, 16.492857142857144),\n",
       " ('San Jose Diridon Caltrain Station', 6, 16.34285714285714),\n",
       " ('San Jose Diridon Caltrain Station', 18, 16.21904761904762),\n",
       " ('San Jose Diridon Caltrain Station', 19, 15.64047619047619),\n",
       " ('San Jose Diridon Caltrain Station', 22, 15.516666666666667),\n",
       " ('San Jose Diridon Caltrain Station', 0, 15.445238095238095),\n",
       " ('San Jose Diridon Caltrain Station', 20, 15.416666666666666),\n",
       " ('San Jose Diridon Caltrain Station', 1, 15.392857142857142),\n",
       " ('San Jose Diridon Caltrain Station', 4, 15.383333333333333)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topavail = avgbyhour.keyBy(lambda x: x[1]) \\\n",
    "                    .sortByKey(ascending=False) \\\n",
    "                    .map(lambda x: (x[1][0][0],x[1][0][1],x[0]))\n",
    "topavail.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
