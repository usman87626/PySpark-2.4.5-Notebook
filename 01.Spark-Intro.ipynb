{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Programming:\n",
    "\n",
    "# i)Introduction to RDDs:\n",
    "\n",
    "A Resilient Distributed Dataset is the most fundamental data object used in Spark Programming.RDDs are datasets within \n",
    "the Spark Application.Most application loads RDD with external data and then create new RDDs by performing operations on these RDDs; these operations are called <strong>Transformations</strong>.This process is repeated until output operation is reached.At last we require <strong>actions</strong> like we want to write the results to the filesystem it would be accomplished through <strong>actions</strong>.\n",
    "\n",
    "In case of PySpark,RDDs are consists of distributed Python objects like lists,tuples and dictionaries.Objects within RDDs(values) can be of float,integer ,strings or any complex types like tuples,dictionary or other lists.\n",
    "\n",
    "Although there are options for persisting RDDs to disks but RDDs are mainly stored in memory to at least these are intended to store in memory.Because one of the initial use of spark was to provide machine learning,Spark RDD's provided a restricted form of shared memory that could make effecient reuse of data for iterative and successive operations.\n",
    "\n",
    "Morever,one of the downside of Hadoop's implementation of MapReduce was that they were storing the data on disks and were moving them at the run time to make copies or use of data that was ensuring the resiliency and fault tolerance but it was more costy in perspective of latency.This limitation was catalyst for development of Spark.Spark introduced the storage of data in memory to analyze the data on runtime as well because the data was growing in volume and there was a need to analyze it on runtime,so Spark was growing.\n",
    "\n",
    "Lets break the term RDD:\n",
    "<ul>\n",
    "    <li>\n",
    "        <strong><b>Resilient:</b></strong> RDDs are Resilient which means that if a node performing an action is lost it can be recreated because Spark knows the lineage for creating the RDDs.\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong><b>Distributed:</b></strong>It means that RDDs are divided into one or many partitions and distributed as in memory collections of objects across the Worker Nodes in the cluster.As discuss above,RDDs provide an effective form of shared memory to exchange data between processes(Executors) on different nodes(Workers).\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong><b>Dataset:</b></strong>It means that RDDs contains records.Records are uniquely identifiable data collections within a dataset.A record can be collection of rows like in relational databases,a line of text in a file or multiple other formats.RDDs are created in such a way that each partition contains unique set of records and can be operated independently.Its example of <strong>shared nothing approach.</strong>\n",
    "    </li>\n",
    "</ul>\n",
    "<h4>More About Spark:</h4>\n",
    "<ul>\n",
    "    <li>Another key propery of RDDs is their immutability i.e Once they are instantiated they cannot be changed through any operation,only you can create new RDDs by applying transformations on these(map or filter functions- we will see these later in notebook).</li>\n",
    "    <br>\n",
    "    <li>\n",
    "        Actions are other operations performed on RDDs.Actions produce output that can be in the form of data from an RDD returned to Driver program or they can store the content of RDD to local filesystem(local,HDFS,S3,others).There are many other actions as well,including returning a count of number of records in RDD.\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "# Lets see an Example:\n",
    "The cell contains sample code to load data into RDD,creating new RDD by applying filter transformation,and then applying action to store the data to disk.We will look everything in detail in upcoming notebooks,its just for mapping concepts with hands-on example:\n",
    "\n",
    "<code>\n",
    "#Load log data from file system\n",
    "logFilesRDD = sc.textFile(\"file:///var/log/hadoop/hdfs/hadoop-hdfs-*\")\n",
    "#filter log records for errors only\n",
    "onlyErrorsRDD = logFilesRDD.filter(lambda line: \"ERROR\" in line)\n",
    "#save onlyErrosRDD as a file\n",
    "onlyErrorsRDD = savaAsTextFile(\"file:///tmp/onlyerrorsrdd*\")\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To know more about RDDs\n",
    "Check this [paper](https://amplab.cs.berkeley.edu/publication/resilient-distributed-datasets-a-fault-tolerant-abstraction-for-in-memory-cluster-computing/) out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
