{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of RDDs\n",
    "Aside from the base RDD class that contains members (properties or attributes and functions)\n",
    "common to all RDDs, there are some specific RDD implementations that enable additional opera-\n",
    "tors and functions. These additional RDD types include the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i)PairRDD: \n",
    "An RDD of key/value pairs. You have already seen this type of RDD as it is\n",
    "automatically created by using the wholeTextFiles() method.\n",
    "\n",
    "# ii)DoubleRDD: \n",
    "An RDD consisting of a collection of double values only. Because the\n",
    "values are of the same numeric type, several additional statistical functions are available,\n",
    "including mean() , sum() , stdev() , variance() , and histogram() , among others.\n",
    "\n",
    "# iii) DataFrame (formerly known as SchemaRDD):\n",
    "A distributed collection of data organized into named and typed columns. \n",
    "A DataFrame is equivalent to a relational table in Spark SQL. \n",
    "DataFrames originated with the read.jdbc() and read.json() functions discussed earlier.\n",
    "\n",
    "# iv) SequenceFileRDD:\n",
    "An RDD created from a SequenceFile, either compressed or\n",
    "uncompressed.\n",
    "\n",
    "# v) HadoopRDD: \n",
    "An RDD that provides core functionality for reading data stored in HDFS\n",
    "using the v1 MapReduce API.\n",
    "\n",
    "# vi) NewHadoopRDD: \n",
    "An RDD that provides core functionality for reading data stored in\n",
    "Hadoop.For example, files in HDFS, sources in HBase, or S3—using the new MapReduce\n",
    "API (org.apache.hadoop.mapreduce).\n",
    "\n",
    "# vii) CoGroupedRDD: \n",
    "An RDD that cogroups its parents. For each key in parent RDDs, the\n",
    "resulting RDD contains a tuple with the list of values for that key. (We will discuss the\n",
    "cogroup() function later in this chapter.)\n",
    "\n",
    "# viii) JdbcRDD: \n",
    "An RDD resulting from a SQL query to a JDBC connection. It is available in the\n",
    "Scala API only.\n",
    "\n",
    "# ix) PartitionPruningRDD: \n",
    "An RDD used to prune RDD partitions or other partitions to avoid\n",
    "launching tasks on all partitions. For example, if you know the RDD is partitioned by range,\n",
    "and the execution DAG has a filter on the key, you can avoid launching tasks on partitions\n",
    "that don’t have the range covering the key.\n",
    "\n",
    "# x) ShuffledRDD: \n",
    "The resulting RDD from a shuffle, such as repartitioning of data.\n",
    "\n",
    "# xi) UnionRDD: \n",
    "An RDD resulting from a union() operation against two or more RDDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other RDD variants, including ParallelCollectionRDD and PythonRDD, which are\n",
    "created from the parallelize() and range() functions discussed previously.\n",
    "\n",
    "Throughout this book, in addition to the base RDD class, you will mainly use the PairRDD,\n",
    "DoubleRDD, and DataFrame RDD classes, but it’s worthwhile to be familiar with all the various\n",
    "RDD types. Documentation and more information about the types of RDDs can be found in the\n",
    "Spark Scala API documentation at https://spark.apache.org/docs/latest/api/scala/index.html."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
