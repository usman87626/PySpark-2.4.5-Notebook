{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD Lineage\n",
    "Spark keeps track of each RDD’s lineage—that is, the sequence of transformations that resulted in\n",
    "the RDD. As discussed previously, every RDD operation recomputes the entire lineage by default\n",
    "unless RDD persistence is requested.\n",
    "In an RDD’s lineage, each RDD has a parent RDD and/or a child RDD. Spark creates a directed\n",
    "acyclic graph (DAG) consisting of dependencies between RDDs. RDDs are processed in stages,\n",
    "which are sets of transformations. RDDs and stages have dependencies that can be narrow or wide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Narrow Dependencies:\n",
    "Narrow dependencies, or narrow operations, are categorized by the following traits:\n",
    "<ul>\n",
    "<li>\n",
    "Operations can collapse into a single stage; for instance, a map() and filter() operation\n",
    "against elements in the same dataset can be processed in a single pass of each element in\n",
    "the dataset.\n",
    "</li><li>\n",
    " Only one child RDD depends on the parent RDD; for instance, an RDD is created from a text\n",
    "file (the parent RDD), with one child RDD to perform the set of transformations in one stage.\n",
    "    </li><li>\n",
    "    No shuffling of data between nodes is required.\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "Narrow operations are preferred because they maximize parallel execution and minimize shuf-\n",
    "fling, which is quite expensive and can be a bottleneck.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide Dependencies:\n",
    "Wide dependencies of wide operations, in contrast, have the following traits:\n",
    "<ul><li>\n",
    "Operations define new stages and often require shuffling. </li><li>\n",
    " RDDs have multiple dependencies; for instance, a join() operation (covered shortly)\n",
    "requires an RDD to be dependent upon two or more parent RDDs.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "Wide operations are unavoidable when grouping, reducing, or joining datasets, but you should be\n",
    "aware of the impacts and overhead involved with these operations.\n",
    "Lineage can be visualized by using the DAG Visualization option link from the Jobs or Stages\n",
    "detail page in the Spark application UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fault Tolerance with RDDs\n",
    "Spark records the lineage of each RDD, including the lineage of all parent RDDs and parents’\n",
    "parents, and so on. Any RDD with all of its partitions can be reconstructed to the state it was in at\n",
    "the time of the failure, which could have resulted from a node failure, for example. Because RDDs\n",
    "are distributed, they can tolerate and recover from the failure of any single node.\n",
    "\n",
    "# Non-deterministic Functions and Fault Tolerance:\n",
    "The use of non-deterministic functions in a Spark program—that is, functions that can\n",
    "produce different output given the same inputs, such as random() —will impact the ability to\n",
    "re-create RDDs in a consistent, repeatable state. This is further complicated if you use the\n",
    "non- deterministic function as a condition, which affects the logic or flow of the program. Use\n",
    "caution when implementing non-deterministic functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
